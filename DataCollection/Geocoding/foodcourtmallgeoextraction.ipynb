{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\xnoob\\documents\\github\\inf2008_ml_grp20\\jupyter_env\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\xnoob\\documents\\github\\inf2008_ml_grp20\\jupyter_env\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please add the following missing content!\n",
    "\"HDP_Hawker and coffeshop listing_for online use_16.5.2018.xlsx\" rename to \"HDP_Hawker_and_coffeeshop.xlsx\"\n",
    "\n",
    "https://ch-api.healthhub.sg/api/public/content/2be093bf58c948bd8e510df83a80914a?v=ee49b3af\n",
    "\n",
    "\"List_of_Malls.txt\" copy and pasted from https://en.wikipedia.org/wiki/List_of_shopping_malls_in_Singapore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "EXCEL_FILE = \"../Data_Raw/HDP_Hawker_and_coffeeshop.xlsx\"\n",
    "CLEANED_HAWKER_CSV = \"Hawker.csv\"\n",
    "HAWKER_COORDS_CSV = \"../Data_Coordinates/Hawker.csv\"\n",
    "\n",
    "MALL_LIST_FILE = \"../Data_Raw/List_of_Malls.txt\"\n",
    "MALL_COORDS_CSV = \"../Data_Coordinates/MallCoordinates.csv\"\n",
    "\n",
    "FAILURE_LOG = \"google_api_failures.json\"\n",
    "ADDRESS_CACHE_FILE = \"address_cache.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Google Maps API Key from environment variables\n",
    "GOOGLE_MAPS_API_KEY = \"Google API Key\"\n",
    "\n",
    "GOOGLE_API_URL = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "session = requests.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and saving JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_file(file_path):\n",
    "    \"\"\"Load JSON file if exists, otherwise return an empty dictionary.\"\"\"\n",
    "    return json.load(open(file_path, \"r\")) if os.path.exists(file_path) else {}\n",
    "\n",
    "\n",
    "def save_json_file(file_path, data):\n",
    "    \"\"\"Save data to a JSON file.\"\"\"\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the hawker dataset by removing duplications based on name of hawker centre/ coffee shop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_hawker_data():\n",
    "    \"\"\"Load and clean the hawker centre data from an Excel file.\"\"\"\n",
    "    print(\"📌 Cleaning hawker centre data...\")\n",
    "\n",
    "    df = pd.read_excel(EXCEL_FILE, usecols=[\"Name of hawker centre/coffee\\nshop\", \"Address\"], engine=\"openpyxl\")\n",
    "    df = df.drop_duplicates().dropna()\n",
    "    df[\"Address\"] = df[\"Address\"].str.strip()\n",
    "\n",
    "    df.to_csv(CLEANED_HAWKER_CSV, index=False, encoding=\"utf-8\")\n",
    "    print(f\"✅ Cleaned data saved to {CLEANED_HAWKER_CSV} ({len(df)} rows)\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch via google api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates_google(address, cache, failure_log):\n",
    "    \"\"\"Fetch latitude and longitude from Google Maps API with caching and failure handling.\"\"\"\n",
    "    if address in cache:\n",
    "        return cache[address]\n",
    "\n",
    "    if address in failure_log:\n",
    "        return None, None\n",
    "\n",
    "    params = {\"address\": f\"{address}, Singapore\", \"region\": \"SG\", \"key\": GOOGLE_MAPS_API_KEY}\n",
    "\n",
    "    try:\n",
    "        response = session.get(GOOGLE_API_URL, params=params, timeout=5)\n",
    "        data = response.json()\n",
    "\n",
    "        if response.status_code == 200 and data.get(\"results\"):\n",
    "            location = data[\"results\"][0][\"geometry\"][\"location\"]\n",
    "            cache[address] = (location[\"lat\"], location[\"lng\"])\n",
    "            save_json_file(ADDRESS_CACHE_FILE, cache)\n",
    "            return location[\"lat\"], location[\"lng\"]\n",
    "\n",
    "        failure_log[address] = True\n",
    "        save_json_file(FAILURE_LOG, failure_log)\n",
    "        return None, None\n",
    "\n",
    "    except requests.RequestException:\n",
    "        failure_log[address] = True\n",
    "        save_json_file(FAILURE_LOG, failure_log)\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_coordinates(df, entity_name=\"Location\"):\n",
    "    \"\"\"Fetch coordinates for each unique address using Google Maps API with progress tracking.\"\"\"\n",
    "    failure_log = load_json_file(FAILURE_LOG)\n",
    "    cache = load_json_file(ADDRESS_CACHE_FILE)\n",
    "    results = []\n",
    "\n",
    "    total_addresses = len(df)\n",
    "    start_time = time.time()\n",
    "\n",
    "    for index, (_, row) in enumerate(df.iterrows(), start=1):\n",
    "        name, address = row[\"Name\"], row[\"Address\"]\n",
    "        lat, lon = get_coordinates_google(address, cache, failure_log)\n",
    "        results.append([name, address, lat, lon])\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        estimated_time_remaining = (elapsed_time / index) * total_addresses - elapsed_time\n",
    "\n",
    "        print(f\"🟢 [{index}/{total_addresses}] {entity_name}: {name} | Lat: {lat}, Lon: {lon} \"\n",
    "              f\"| Elapsed: {elapsed_time:.2f}s | ETA: {estimated_time_remaining:.2f}s\")\n",
    "\n",
    "        time.sleep(0.2)  # API rate limiting\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(csv_file, data, headers):\n",
    "    \"\"\"Save data to a CSV file.\"\"\"\n",
    "    with open(csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(headers)\n",
    "        writer.writerows(data)\n",
    "    print(f\"✅ Data saved to {csv_file} ({len(data)} rows)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load mall from file .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_malls_from_file():\n",
    "    \"\"\"Read mall names and their regions from a text file.\"\"\"\n",
    "    regions = {}\n",
    "    current_region = None\n",
    "    with open(MALL_LIST_FILE, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                if line in [\"Central\", \"East\", \"North\", \"North East\", \"North West\", \"South\", \"West\"]:\n",
    "                    current_region = line\n",
    "                    regions[current_region] = []\n",
    "                elif current_region:\n",
    "                    regions[current_region].append(line)\n",
    "    return regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_existing_data(csv_file):\n",
    "    \"\"\"Load existing mall data from a CSV file if available.\"\"\"\n",
    "    existing_data = {}\n",
    "    if os.path.exists(csv_file):\n",
    "        with open(csv_file, \"r\", encoding=\"utf-8\") as file:\n",
    "            reader = csv.reader(file)\n",
    "            next(reader)  # Skip header\n",
    "            for row in reader:\n",
    "                mall_name, region, lat, lon = row\n",
    "                existing_data[mall_name.lower()] = [mall_name, region, lat, lon]\n",
    "    return existing_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch and update the mall csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_malls(regions):\n",
    "    \"\"\"Process malls, reuse existing coordinates, and only fetch missing ones.\"\"\"\n",
    "    failure_log = load_json_file(FAILURE_LOG)\n",
    "    cache = load_json_file(ADDRESS_CACHE_FILE)\n",
    "    existing_mall_data = load_existing_data(MALL_COORDS_CSV)\n",
    "    results = []\n",
    "\n",
    "    malls_list = [(region, mall) for region, malls in regions.items() for mall in malls]\n",
    "    total_malls = len(malls_list)\n",
    "    start_time = time.time()\n",
    "\n",
    "    for index, (region, mall) in enumerate(malls_list, start=1):\n",
    "        mall_cleaned = mall.split(\"(\")[0].strip()\n",
    "        existing_match = difflib.get_close_matches(mall_cleaned.lower(), existing_mall_data.keys(), n=1, cutoff=0.8)\n",
    "\n",
    "        if existing_match:\n",
    "            mall_name, existing_region, lat, lon = existing_mall_data[existing_match[0]]\n",
    "            if lat and lon:\n",
    "                print(f\"⏩ Skipping: {mall_cleaned} (Already in dataset)\")\n",
    "            else:\n",
    "                lat, lon = get_coordinates_google(mall_cleaned, cache, failure_log)\n",
    "        else:\n",
    "            lat, lon = get_coordinates_google(mall_cleaned, cache, failure_log)\n",
    "\n",
    "        results.append([mall_cleaned, region, lat, lon])\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        estimated_time_remaining = (elapsed_time / index) * total_malls - elapsed_time\n",
    "\n",
    "        print(f\"🟢 [{index}/{total_malls}] Mall: {mall_cleaned} | Lat: {lat}, Lon: {lon} \"\n",
    "              f\"| Elapsed: {elapsed_time:.2f}s | ETA: {estimated_time_remaining:.2f}s\")\n",
    "\n",
    "        time.sleep(0.2)  # API rate limiting\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Hawker centre coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Cleaning and fetching hawker centre coordinates...\n",
      "📌 Cleaning hawker centre data...\n",
      "✅ Cleaned data saved to Hawker.csv (961 rows)\n",
      "🟢 [1/961] Hawker Centre: H23 Eating House | Lat: 1.3212494, Lon: 103.8866968 | Elapsed: 0.00s | ETA: 0.96s\n",
      "🟢 [2/961] Hawker Centre: 117 Aljunied Market & Food\n",
      "Centre | Lat: 1.3206162, Lon: 103.8869842 | Elapsed: 0.20s | ETA: 96.52s\n",
      "🟢 [3/961] Hawker Centre: Sin Hin Eating House | Lat: 1.3200279, Lon: 103.8868022 | Elapsed: 0.40s | ETA: 128.32s\n",
      "🟢 [4/961] Hawker Centre: Chang Cheng Food & Beverage | Lat: 1.3200279, Lon: 103.8868022 | Elapsed: 0.60s | ETA: 144.12s\n",
      "🟢 [5/961] Hawker Centre: Lian Soon Reality Pte. Ltd | Lat: 1.3760127, Lon: 104.0028648 | Elapsed: 0.80s | ETA: 153.53s\n",
      "🟢 [6/961] Hawker Centre: Yue Hua Food Place Pte. Ltd. | Lat: 1.3298365, Lon: 103.9309174 | Elapsed: 1.00s | ETA: 159.78s\n",
      "🟢 [7/961] Hawker Centre: Lucky 5 | Lat: 1.3284617, Lon: 103.9306227 | Elapsed: 1.21s | ETA: 164.25s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m df_hawker = clean_hawker_data()\n\u001b[32m      3\u001b[39m df_hawker = df_hawker.rename(columns={\u001b[33m\"\u001b[39m\u001b[33mName of hawker centre/coffee\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mshop\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mName\u001b[39m\u001b[33m\"\u001b[39m})\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m hawker_results = \u001b[43mfetch_coordinates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_hawker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHawker Centre\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m save_to_csv(HAWKER_COORDS_CSV, hawker_results, [\u001b[33m\"\u001b[39m\u001b[33mHawker Centre / Coffeeshop\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAddress\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mLatitude\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mLongitude\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mfetch_coordinates\u001b[39m\u001b[34m(df, entity_name)\u001b[39m\n\u001b[32m     16\u001b[39m     estimated_time_remaining = (elapsed_time / index) * total_addresses - elapsed_time\n\u001b[32m     18\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m🟢 [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_addresses\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mentity_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Lat: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlat\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Lon: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlon\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     19\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m| Elapsed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms | ETA: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimated_time_remaining\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# API rate limiting\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(\"📌 Cleaning and fetching hawker centre coordinates...\")\n",
    "df_hawker = clean_hawker_data()\n",
    "df_hawker = df_hawker.rename(columns={\"Name of hawker centre/coffee\\nshop\": \"Name\"})\n",
    "hawker_results = fetch_coordinates(df_hawker, \"Hawker Centre\")\n",
    "save_to_csv(HAWKER_COORDS_CSV, hawker_results, [\"Hawker Centre / Coffeeshop\", \"Address\", \"Latitude\", \"Longitude\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Mall coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Processing malls and fetching coordinates...\n",
      "⏩ Skipping: 100 AM (Already in dataset)\n",
      "🟢 [1/174] Mall: 100 AM | Lat: 1.2749931, Lon: 103.8435825 | Elapsed: 0.00s | ETA: 0.00s\n",
      "⏩ Skipping: 313@Somerset (Already in dataset)\n",
      "🟢 [2/174] Mall: 313@Somerset | Lat: 1.3010451, Lon: 103.8385792 | Elapsed: 0.20s | ETA: 17.31s\n",
      "⏩ Skipping: Aperia (Already in dataset)\n",
      "🟢 [3/174] Mall: Aperia | Lat: 1.310458, Lon: 103.8641669 | Elapsed: 0.40s | ETA: 22.92s\n",
      "⏩ Skipping: Balestier Hill Shopping Centre (Already in dataset)\n",
      "🟢 [4/174] Mall: Balestier Hill Shopping Centre | Lat: 1.3258546, Lon: 103.8428618 | Elapsed: 0.60s | ETA: 25.64s\n",
      "⏩ Skipping: Bugis Cube (Already in dataset)\n",
      "🟢 [5/174] Mall: Bugis Cube | Lat: 1.2981918, Lon: 103.8556572 | Elapsed: 0.80s | ETA: 27.20s\n",
      "⏩ Skipping: Bugis Junction (Already in dataset)\n",
      "🟢 [6/174] Mall: Bugis Junction | Lat: 1.2993754, Lon: 103.8555261 | Elapsed: 1.01s | ETA: 28.15s\n",
      "⏩ Skipping: Bugis+ (Already in dataset)\n",
      "🟢 [7/174] Mall: Bugis+ | Lat: 1.2995955, Lon: 103.8542191 | Elapsed: 1.21s | ETA: 28.80s\n",
      "⏩ Skipping: Capitol Piazza (Already in dataset)\n",
      "🟢 [8/174] Mall: Capitol Piazza | Lat: 1.2929876, Lon: 103.8511619 | Elapsed: 1.41s | ETA: 29.21s\n",
      "⏩ Skipping: Cathay Cineleisure Orchard (Already in dataset)\n",
      "🟢 [9/174] Mall: Cathay Cineleisure Orchard | Lat: 1.3016866, Lon: 103.8365735 | Elapsed: 1.61s | ETA: 29.50s\n",
      "⏩ Skipping: Clarke Quay Central (Already in dataset)\n",
      "🟢 [10/174] Mall: Clarke Quay Central | Lat: 1.2890252, Lon: 103.8466098 | Elapsed: 1.81s | ETA: 29.68s\n",
      "⏩ Skipping: The Centrepoint (Already in dataset)\n",
      "🟢 [11/174] Mall: The Centrepoint | Lat: 1.3012253, Lon: 103.8398652 | Elapsed: 2.01s | ETA: 29.80s\n",
      "⏩ Skipping: City Square Mall (Already in dataset)\n",
      "🟢 [12/174] Mall: City Square Mall | Lat: 1.3114516, Lon: 103.8561608 | Elapsed: 2.21s | ETA: 29.87s\n",
      "⏩ Skipping: City Gate Mall (Already in dataset)\n",
      "🟢 [13/174] Mall: City Gate Mall | Lat: 1.3022509, Lon: 103.8625132 | Elapsed: 2.41s | ETA: 29.89s\n",
      "⏩ Skipping: CityLink Mall (Already in dataset)\n",
      "🟢 [14/174] Mall: CityLink Mall | Lat: 1.2913005, Lon: 103.8551976 | Elapsed: 2.61s | ETA: 29.88s\n",
      "⏩ Skipping: Duo (Already in dataset)\n",
      "🟢 [15/174] Mall: Duo | Lat: 1.352083, Lon: 103.819836 | Elapsed: 2.82s | ETA: 29.84s\n",
      "⏩ Skipping: Far East Plaza (Already in dataset)\n",
      "🟢 [16/174] Mall: Far East Plaza | Lat: 1.3070854, Lon: 103.8333034 | Elapsed: 3.02s | ETA: 29.79s\n",
      "⏩ Skipping: Funan (Already in dataset)\n",
      "🟢 [17/174] Mall: Funan | Lat: 1.2912647, Lon: 103.8501932 | Elapsed: 3.22s | ETA: 29.72s\n",
      "⏩ Skipping: Great World City (Already in dataset)\n",
      "🟢 [18/174] Mall: Great World City | Lat: 1.2936417, Lon: 103.8319293 | Elapsed: 3.42s | ETA: 29.63s\n",
      "⏩ Skipping: GRiD (Already in dataset)\n",
      "🟢 [19/174] Mall: GRiD | Lat: 1.3001949, Lon: 103.8492265 | Elapsed: 3.62s | ETA: 29.52s\n",
      "⏩ Skipping: HDB Hub (Already in dataset)\n",
      "🟢 [20/174] Mall: HDB Hub | Lat: 1.3320022, Lon: 103.8494339 | Elapsed: 3.82s | ETA: 29.41s\n",
      "⏩ Skipping: Holland Village Shopping Mall (Already in dataset)\n",
      "🟢 [21/174] Mall: Holland Village Shopping Mall | Lat: 1.310912, Lon: 103.7951937 | Elapsed: 4.02s | ETA: 29.29s\n",
      "⏩ Skipping: ION Orchard (Already in dataset)\n",
      "🟢 [22/174] Mall: ION Orchard | Lat: 1.3039288, Lon: 103.8319492 | Elapsed: 4.22s | ETA: 29.17s\n",
      "⏩ Skipping: Junction 8 (Already in dataset)\n",
      "🟢 [23/174] Mall: Junction 8 | Lat: 1.3506808, Lon: 103.8487631 | Elapsed: 4.42s | ETA: 29.04s\n",
      "⏩ Skipping: Knightsbridge[2] (Already in dataset)\n",
      "🟢 [24/174] Mall: Knightsbridge[2] | Lat: 1.352083, Lon: 103.819836 | Elapsed: 4.62s | ETA: 28.90s\n",
      "⏩ Skipping: Liat Towers (Already in dataset)\n",
      "🟢 [25/174] Mall: Liat Towers | Lat: 1.3051925, Lon: 103.8305905 | Elapsed: 4.82s | ETA: 28.75s\n",
      "⏩ Skipping: Lucky Plaza (Already in dataset)\n",
      "🟢 [26/174] Mall: Lucky Plaza | Lat: 1.3045795, Lon: 103.8340621 | Elapsed: 5.03s | ETA: 28.61s\n",
      "⏩ Skipping: Marina Bay Sands (Already in dataset)\n",
      "🟢 [27/174] Mall: Marina Bay Sands | Lat: 1.2837575, Lon: 103.8591065 | Elapsed: 5.23s | ETA: 28.45s\n",
      "⏩ Skipping: The Shoppes at Marina Bay Sands (Already in dataset)\n",
      "🟢 [28/174] Mall: The Shoppes at Marina Bay Sands | Lat: 1.2836889, Lon: 103.8591846 | Elapsed: 5.43s | ETA: 28.30s\n",
      "⏩ Skipping: Marina Bay Link Mall (Already in dataset)\n",
      "🟢 [29/174] Mall: Marina Bay Link Mall | Lat: 1.2795303, Lon: 103.8543391 | Elapsed: 5.63s | ETA: 28.14s\n",
      "⏩ Skipping: Marina Square (Already in dataset)\n",
      "🟢 [30/174] Mall: Marina Square | Lat: 1.2911534, Lon: 103.8576778 | Elapsed: 5.83s | ETA: 27.98s\n",
      "⏩ Skipping: Millenia Walk (Already in dataset)\n",
      "🟢 [31/174] Mall: Millenia Walk | Lat: 1.2916585, Lon: 103.8597629 | Elapsed: 6.03s | ETA: 27.82s\n",
      "⏩ Skipping: Mustafa Shopping Centre (Already in dataset)\n",
      "🟢 [32/174] Mall: Mustafa Shopping Centre | Lat: 1.3099676, Lon: 103.8554251 | Elapsed: 6.23s | ETA: 27.65s\n",
      "⏩ Skipping: Ngee Ann City (Already in dataset)\n",
      "🟢 [33/174] Mall: Ngee Ann City | Lat: 1.3025572, Lon: 103.834568 | Elapsed: 6.43s | ETA: 27.49s\n",
      "⏩ Skipping: One Holland Village (Already in dataset)\n",
      "🟢 [34/174] Mall: One Holland Village | Lat: 1.3103869, Lon: 103.7943653 | Elapsed: 6.64s | ETA: 27.32s\n",
      "⏩ Skipping: Orchard Central (Already in dataset)\n",
      "🟢 [35/174] Mall: Orchard Central | Lat: 1.3007639, Lon: 103.8397236 | Elapsed: 6.84s | ETA: 27.15s\n",
      "⏩ Skipping: Orchard Gateway (Already in dataset)\n",
      "🟢 [36/174] Mall: Orchard Gateway | Lat: 1.3007002, Lon: 103.8394225 | Elapsed: 7.04s | ETA: 26.97s\n",
      "⏩ Skipping: Orchard Plaza (Already in dataset)\n",
      "🟢 [37/174] Mall: Orchard Plaza | Lat: 1.3009768, Lon: 103.8410562 | Elapsed: 7.24s | ETA: 26.80s\n",
      "⏩ Skipping: Midpoint Orchard (Already in dataset)\n",
      "🟢 [38/174] Mall: Midpoint Orchard | Lat: 1.3018235, Lon: 103.838442 | Elapsed: 7.44s | ETA: 26.62s\n",
      "⏩ Skipping: Palais Renaissance (Already in dataset)\n",
      "🟢 [39/174] Mall: Palais Renaissance | Lat: 1.306542, Lon: 103.8295263 | Elapsed: 7.64s | ETA: 26.44s\n",
      "⏩ Skipping: People's Park Centre (Already in dataset)\n",
      "🟢 [40/174] Mall: People's Park Centre | Lat: 1.285631, Lon: 103.8440929 | Elapsed: 7.84s | ETA: 26.26s\n",
      "⏩ Skipping: People's Park Complex (Already in dataset)\n",
      "🟢 [41/174] Mall: People's Park Complex | Lat: 1.2842112, Lon: 103.8426423 | Elapsed: 8.04s | ETA: 26.08s\n",
      "⏩ Skipping: Plaza Singapura (Already in dataset)\n",
      "🟢 [42/174] Mall: Plaza Singapura | Lat: 1.3000678, Lon: 103.8447831 | Elapsed: 8.24s | ETA: 25.90s\n",
      "⏩ Skipping: Raffles City (Already in dataset)\n",
      "🟢 [43/174] Mall: Raffles City | Lat: 1.352083, Lon: 103.819836 | Elapsed: 8.44s | ETA: 25.72s\n",
      "⏩ Skipping: Scotts Square (Already in dataset)\n",
      "🟢 [44/174] Mall: Scotts Square | Lat: 1.3058788, Lon: 103.8329554 | Elapsed: 8.64s | ETA: 25.54s\n",
      "⏩ Skipping: Shaw House and Centre (Already in dataset)\n",
      "🟢 [45/174] Mall: Shaw House and Centre | Lat: 1.3062932, Lon: 103.8318472 | Elapsed: 8.84s | ETA: 25.35s\n",
      "⏩ Skipping: Sim Lim Square (Already in dataset)\n",
      "🟢 [46/174] Mall: Sim Lim Square | Lat: 1.3030433, Lon: 103.8529208 | Elapsed: 9.05s | ETA: 25.17s\n",
      "⏩ Skipping: Singapore Shopping Centre (Already in dataset)\n",
      "🟢 [47/174] Mall: Singapore Shopping Centre | Lat: 1.2981622, Lon: 103.844132 | Elapsed: 9.25s | ETA: 24.98s\n",
      "⏩ Skipping: The South Beach (Already in dataset)\n",
      "🟢 [48/174] Mall: The South Beach | Lat: 1.2957395, Lon: 103.8566136 | Elapsed: 9.45s | ETA: 24.80s\n",
      "⏩ Skipping: Square 2 (Already in dataset)\n",
      "🟢 [49/174] Mall: Square 2 | Lat: 1.3208322, Lon: 103.8441474 | Elapsed: 9.65s | ETA: 24.61s\n",
      "⏩ Skipping: Sunshine Plaza (Already in dataset)\n",
      "🟢 [50/174] Mall: Sunshine Plaza | Lat: 1.3004038, Lon: 103.8511253 | Elapsed: 9.85s | ETA: 24.42s\n",
      "⏩ Skipping: Suntec City (Already in dataset)\n",
      "🟢 [51/174] Mall: Suntec City | Lat: 1.2950324, Lon: 103.8583015 | Elapsed: 10.05s | ETA: 24.24s\n",
      "⏩ Skipping: Tanglin Mall (Already in dataset)\n",
      "🟢 [52/174] Mall: Tanglin Mall | Lat: 1.304834, Lon: 103.8238271 | Elapsed: 10.25s | ETA: 24.05s\n",
      "⏩ Skipping: Tanjong Pagar Centre (Already in dataset)\n",
      "🟢 [53/174] Mall: Tanjong Pagar Centre | Lat: 1.276951, Lon: 103.8458291 | Elapsed: 10.45s | ETA: 23.86s\n",
      "⏩ Skipping: Tekka Centre (Already in dataset)\n",
      "🟢 [54/174] Mall: Tekka Centre | Lat: 1.3063839, Lon: 103.8507014 | Elapsed: 10.65s | ETA: 23.67s\n",
      "⏩ Skipping: The Adelphi (Already in dataset)\n",
      "🟢 [55/174] Mall: The Adelphi | Lat: 1.2911845, Lon: 103.8512167 | Elapsed: 10.85s | ETA: 23.48s\n",
      "⏩ Skipping: The Paragon (Already in dataset)\n",
      "🟢 [56/174] Mall: The Paragon | Lat: 1.3039633, Lon: 103.8360565 | Elapsed: 11.05s | ETA: 23.29s\n",
      "⏩ Skipping: Tiong Bahru Plaza (Already in dataset)\n",
      "🟢 [57/174] Mall: Tiong Bahru Plaza | Lat: 1.2866535, Lon: 103.8271459 | Elapsed: 11.25s | ETA: 23.10s\n",
      "⏩ Skipping: The Poiz (Already in dataset)\n",
      "🟢 [58/174] Mall: The Poiz | Lat: 1.3321537, Lon: 103.8687368 | Elapsed: 11.46s | ETA: 22.91s\n",
      "⏩ Skipping: Thomson Plaza (Already in dataset)\n",
      "🟢 [59/174] Mall: Thomson Plaza | Lat: 1.3548586, Lon: 103.8308906 | Elapsed: 11.66s | ETA: 22.72s\n",
      "⏩ Skipping: United Square (Already in dataset)\n",
      "🟢 [60/174] Mall: United Square | Lat: 1.3171849, Lon: 103.8436045 | Elapsed: 11.86s | ETA: 22.53s\n",
      "⏩ Skipping: Thomson V (Already in dataset)\n",
      "🟢 [61/174] Mall: Thomson V | Lat: 1.353405, Lon: 103.8357573 | Elapsed: 12.06s | ETA: 22.34s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m📌 Processing malls and fetching coordinates...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m regions = load_malls_from_file()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m mall_results = \u001b[43mprocess_malls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m save_to_csv(MALL_COORDS_CSV, mall_results, [\u001b[33m\"\u001b[39m\u001b[33mMall Name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mRegion\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mLatitude\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mLongitude\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mprocess_malls\u001b[39m\u001b[34m(regions)\u001b[39m\n\u001b[32m     28\u001b[39m     estimated_time_remaining = (elapsed_time / index) * total_malls - elapsed_time\n\u001b[32m     30\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m🟢 [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_malls\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Mall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmall_cleaned\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Lat: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlat\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Lon: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlon\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     31\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m| Elapsed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms | ETA: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimated_time_remaining\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# API rate limiting\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(\"📌 Processing malls and fetching coordinates...\")\n",
    "regions = load_malls_from_file()\n",
    "mall_results = process_malls(regions)\n",
    "save_to_csv(MALL_COORDS_CSV, mall_results, [\"Mall Name\", \"Region\", \"Latitude\", \"Longitude\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
